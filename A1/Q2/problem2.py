# -*- coding: utf-8 -*-
"""problem2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XsVjbrLOf6f360jX1Sw6o36FmP5h9SjN
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


file_path = 'cm_dataset_2.csv'
data = pd.read_csv(file_path,header=None)

#QUESTION 2A
#this is for random centroids then initializations , 5 cases.


data_array = data.values

def distance(x1, x2):
    return np.sum((x1 - x2) ** 2)

def error(cluster1, cluster2, mean1, mean2):
    return np.sum([distance(point, mean1) for point in cluster1]) + np.sum([distance(point, mean2) for point in cluster2])

num_iterations = 5
errors = []

for _ in range(num_iterations):
    random_indices = np.random.permutation(len(data_array))
    centroid1 = data_array[random_indices[0]]
    centroid2 = data_array[random_indices[1]]

    cluster1 = []
    cluster2 = []
    for point in data_array:
        if distance(point, centroid1) < distance(point, centroid2):
            cluster1.append(point)
        else:
            cluster2.append(point)

    mean1 = np.mean(cluster1, axis=0)
    mean2 = np.mean(cluster2, axis=0)
    error_cluster = [error(cluster1, cluster2, mean1, mean2)]

    reassigned = True

    while reassigned:
        reassigned = False
        new_cluster1 = []
        new_cluster2 = []

        for data_point in data_array:
            dist1 = distance(data_point, mean1)
            dist2 = distance(data_point, mean2)
            if dist1 < dist2:
                new_cluster1.append(data_point)
            else:
                new_cluster2.append(data_point)

        new_mean1 = np.mean(new_cluster1, axis=0)
        new_mean2 = np.mean(new_cluster2, axis=0)

        if not np.array_equal(new_mean1, mean1) or not np.array_equal(new_mean2, mean2):
            reassigned = True

        cluster1 = np.array(new_cluster1)
        cluster2 = np.array(new_cluster2)
        mean1 = new_mean1
        mean2 = new_mean2

        error_cluster.append(error(cluster1, cluster2, mean1, mean2))


    errors.append(error_cluster)

for i, error_cluster in enumerate(errors):
    plt.plot(range(len(error_cluster)), error_cluster, label=f'Initialization {i+1}')
    plt.xlabel('Iteration')
    plt.ylabel('Error')
    plt.title(f'Error Variation with Iteration for Initialization {i+1}')
    plt.legend()
    plt.show()

    colors = ['blue', 'red']
    plt.figure(figsize=(8, 6))
    plt.scatter(cluster1[:, 0], cluster1[:, 1], color=colors[0], label='Cluster 1')
    plt.scatter(cluster2[:, 0], cluster2[:, 1], color=colors[1], label='Cluster 2')
    plt.scatter([mean1[0]], [mean1[1]], color='green', marker='x', label='Centroid 1')
    plt.scatter([mean2[0]], [mean2[1]], color='orange', marker='x', label='Centroid 2')
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title(f'Clustering (Initialization {i+1})')
    plt.legend()
    plt.show()

#QUESTION 2B




def kmeans(data_array, k):
    np.random.seed(42)
    centroids_indices = np.random.choice(len(data_array), size=k, replace=False)
    centroids = data_array[centroids_indices]

    cluster_assignments = np.zeros(len(data_array))
    cluster_errors = []

    while True:
        for i, point in enumerate(data_array):
            distances = [distance(point, centroid) for centroid in centroids]
            cluster_assignments[i] = np.argmin(distances)

        new_centroids = np.array([np.mean(data_array[cluster_assignments == i], axis=0) for i in range(k)])

        if np.allclose(centroids, new_centroids):
            break

        centroids = new_centroids

        total_error = sum([distance(point, centroids[int(cluster_assignments[i])]) for i, point in enumerate(data_array)])
        cluster_errors.append(total_error)

    return centroids, cluster_assignments,cluster_errors

def voronoi_diagram(means, width, height):
    x, y = np.meshgrid(np.arange(-width, width, 0.1), np.arange(-height, height, 0.1))
    assignments = np.zeros_like(x, dtype=int)
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            distances = np.linalg.norm(means - [x[i, j], y[i, j]], axis=1)
            assignments[i, j] = np.argmin(distances)
    return x, y, assignments

data_array = data.values

width = np.max(data_array[:, 0]) - np.min(data_array[:, 0])
height = np.max(data_array[:, 1]) - np.min(data_array[:, 1])

for k in range(2, 6):
    centroids, cluster_assignments, _ = kmeans(data_array, k)

    x_voronoi, y_voronoi, assignments = voronoi_diagram(centroids, width, height)
    plt.figure(figsize=(8, 6))
    plt.contourf(x_voronoi, y_voronoi, assignments, levels=np.arange(k + 1) - 0.5, cmap='viridis', alpha=0.5)
    plt.scatter(data_array[:, 0], data_array[:, 1], c=cluster_assignments, cmap='viridis', marker='.')
    plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', label='Centroids')
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title(f'K-means Clustering with K={k}')
    plt.legend()
    plt.colorbar()
    plt.show()

#QUESTION 2C

def top2vectorspoly(data_set,d):
   kernel_m_d = ((np.dot(data_set, data_set.T) + 1) ** d)

   n = kernel_m_d.shape[0]
   eigenvalues, eigenvectors = np.linalg.eigh(kernel_m_d)
   sorted_indices = np.flip(np.argsort(eigenvalues))
   sorted_eigenvectors = eigenvectors[:, sorted_indices]
   h_eigenvectors = sorted_eigenvectors[:, :2]
   normalized_matrix = h_eigenvectors / np.linalg.norm(h_eigenvectors, axis=1, keepdims=True)

   return normalized_matrix
def gaussian_kernel_pairwise_distances(x,y,sigma):
   return (np.exp((-np.linalg.norm(x - y) ** 2)/ (2 * (sigma ** 2))))

def top2vectorsgaussian(data_set, sigma):
    new_matrix = np.empty((1000, 1000))

    for i in range(1000):
        for j in range(1000):
            new_matrix[i, j] = gaussian_kernel_pairwise_distances(data_set[i], data_set[j], sigma)

    eigenvalues, eigenvectors = np.linalg.eigh(new_matrix)
    sorted_indices = np.flip(np.argsort(eigenvalues))
    sorted_eigenvectors = eigenvectors[:, sorted_indices]
    h_eigenvectors = sorted_eigenvectors[:, :2]

    zero_rows = np.all(h_eigenvectors == 0, axis=1)
    non_zero_indices = np.where(~zero_rows)

    if np.any(zero_rows):
        normalized_matrix = h_eigenvectors.copy()
        normalized_matrix[zero_rows] = 0
    else:
        norm = np.linalg.norm(h_eigenvectors, axis=1, keepdims=True)
        normalized_matrix = h_eigenvectors / norm

    return normalized_matrix


def kmeans(data_arrayy, k):
    np.random.seed(42)
    centroids_indices = np.random.choice(len(data_arrayy), size=k, replace=False)
    centroids = data_arrayy[centroids_indices]

    cluster_assignments = np.zeros(len(data_arrayy))
    cluster_errors = []

    while True:
        prev_centroids = centroids.copy()  # Store previous centroids

        for i, point in enumerate(data_arrayy):
            distances = [distance(point, centroid) for centroid in centroids]
            cluster_assignments[i] = np.argmin(distances)

        new_centroids = np.array([np.mean(data_arrayy[cluster_assignments == i], axis=0) if np.sum(cluster_assignments == i) > 0 else centroids[i] for i in range(k)])

        if np.allclose(centroids, new_centroids):
            break

        centroids = new_centroids

        total_error = sum([distance(point, centroids[int(cluster_assignments[i])]) for i, point in enumerate(data_arrayy)])
        cluster_errors.append(total_error)

    return centroids, cluster_assignments, cluster_errors



for d in range(2,7):
   centroids, cluster_assignments, _ = kmeans(top2vectorspoly(data.values,d),2)
   data_array = top2vectorspoly(data.values,d)
   plt.figure(figsize=(8, 6))
   plt.scatter(data_array[:, 0], data_array[:, 1], c=cluster_assignments,cmap='viridis', marker='.')
   plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', label='Centroids')
   plt.xlabel('X')
   plt.ylabel('Y')
   plt.title(f'K-means Clustering with kernel K={d}')
   plt.legend()
   plt.show()

sigmas = [0.00001,0.1,1,10,100,1000,10000]

for sigma in sigmas:
   centroids, cluster_assignments, _ = kmeans(top2vectorsgaussian(data.values,sigma),2)
   data_array = top2vectorsgaussian(data.values,sigma)
   plt.figure(figsize=(8, 6))
   plt.scatter(data_array[:, 0], data_array[:, 1], c=cluster_assignments,cmap='viridis', marker='.')
   plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', label='Centroids')
   plt.xlabel('X')
   plt.ylabel('Y')
   plt.title(f'K-means Clustering with kernel K={sigma}')
   plt.legend()
   plt.show()

#QUESTION 2D
#polynomial kernel with degree d


data_arr = data.values
dd = [2,3,4,5,100,1000]
for d in dd:
 norm = top2vectorspoly(data_arr,d)
 cluster_assignmentss = np.zeros(len(data_arr))


 for i,data in enumerate(norm):
    cluster_assignmentss[i]=np.argmax(data)

 centroidss = np.array([np.mean(data_arr[cluster_assignmentss == i], axis=0) for i in range(2)])
 plt.figure(figsize=(8, 6))
 plt.scatter(data_arr[:, 0], data_arr[:, 1], c=cluster_assignmentss,cmap='viridis', marker='.')
 plt.scatter(centroidss[:, 0], centroidss[:, 1], c='red', marker='x', label='Centroids')
 plt.xlabel('X')
 plt.ylabel('Y')
 plt.title(f'K-means Clustering with kernel K={d}')
 plt.legend()
 plt.show()

#QUESTION 2D
#gaussian kernel with degree d

data_arr = data.values
sigmas = [0.01,0.1,1,10,100,1000]
for sigma in sigmas:
 norm = top2vectorsgaussian(data_arr,sigma)
 cluster_assignmentss = np.zeros(len(data_arr))


 for i,data in enumerate(norm):
    cluster_assignmentss[i]=np.argmax(data)

 centroidss = np.array([np.mean(data_arr[cluster_assignmentss == i], axis=0) for i in range(2)])
 plt.figure(figsize=(8, 6))
 plt.scatter(data_arr[:, 0], data_arr[:, 1], c=cluster_assignmentss,cmap='viridis', marker='.')
 plt.scatter(centroidss[:, 0], centroidss[:, 1], c='red', marker='x', label='Centroids')
 plt.xlabel('X')
 plt.ylabel('Y')
 plt.title(f'K-means Clustering with kernel K={sigma}')
 plt.legend()
 plt.show()

